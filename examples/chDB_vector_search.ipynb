{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/chdb-io/chdb/raw/main/docs/_static/snake-chdb.png\" height=100>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by ClickHouse Blog: [ANN Vector Search with SQL-powered LSH & Random Projections](https://clickhouse.com/blog/approximate-nearest-neighbour-ann-with-sql-powered-local-sensitive-hashing-lsh-random-projections). \n",
    "\n",
    "This demo will show how to use chDB to make a simple search engine for a set of movies.\n",
    "```\n",
    "movieId,embedding\n",
    "318,\"[-0.32907996  3.2970035   0.15050603  1.9187577  -5.8646975  -3.7843416\n",
    " -2.6874192  -6.161338    1.98583    -2.6736846   2.1889842   5.162994\n",
    "  1.654852   -0.7761136   1.5172766  -0.85932654]\"\n",
    "296,\"[-0.01519391  2.443479   -1.480839    0.10609777 -5.6971617  -1.3988643\n",
    " -4.1634355  -6.399832    4.8691964  -2.7901962   1.738929    3.839515\n",
    "  1.5430368   1.4577994   0.56058794 -0.9734406 ]\"\n",
    "356,\"[-1.8876978   1.6772441  -1.9821857  -0.93794477 -2.5182424  -3.8408334\n",
    " -3.87617    -4.512172    0.8053944  -2.081389    1.454333    6.7315516\n",
    "  0.22428921  0.72071487  2.211912   -1.3959718 ]\"\n",
    "593,\"[-1.4681095   2.4807196  -2.990346    0.239727   -5.800576   -2.9217808\n",
    " -2.9491336  -6.646222    4.2070146  -2.650232    0.6342644   5.38617\n",
    "  1.0954435  -0.71700466  0.43723348 -0.8792468 ]\"\n",
    "2571,\"[-2.5742574   1.3490096  -2.0755954   3.0196552  -7.46083    -3.2669234\n",
    " -5.8962264  -4.022377    0.9717742   0.75643456  3.016018    4.7698874\n",
    " -0.34867725  3.7842882   0.4231439  -0.81689113]\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation systems these years\n",
    "\n",
    "The recommendation system has made several major advancements over the past 10 years:\n",
    "\n",
    "1. 2009-2015: LR (Logistic Regression) combined with sophisticated feature engineering defeated SVM and collaborative filtering, which were algorithms of the previous generation.\n",
    "1. 2012-2015: NN (Neural Networks) changed the CV (Computer Vision) and NLP (Natural Language Processing) industries, then returned to the recommendation system field, greatly reducing the importance of traditional skill in feature combination.\n",
    "1. 2013: Embedding was taken out from Google's archives and later developed into techniques like Item2vec, sparking a trend in mining user behavior.\n",
    "1. 2015-2016: Wide & Deep inspired \"grafting\" NN with various old models.\n",
    "1. 2016-2017: Experienced a strong counterattack from tree models such as XGBoost and LightGBM that were fast, good, and efficient.\n",
    "1. 2017: Transformer became popularized to the point where \"Attention Is All You Need.\"\n",
    "1. 2018-now: Mainly focused on deep exploration of features, especially user features. Representatively famous is DIEN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this demo\n",
    "\n",
    "Item2vec technology is developed based on Word2vec. Its core idea is to treat the user's historical behavior sequence as a sentence, and then train the vector representation of each item through Word2vec. Finally, item recommendations are made based on the similarity of item vectors. The core of Item2vec technology is to treat the user's historical behavior sequence as a sentence, and then train the vector representation of each item through Word2vec. Finally, item recommendations are made based on the similarity of item vectors.\n",
    "\n",
    "The main purpose of this demo is to demonstrate how to train the vector representation of items using Word2vec and make item recommendations based on the similarity of item vectors. It mainly consists of 4 parts:\n",
    "1. Prepare item sequences based on user behavior.\n",
    "2. Train a CBOW model using the Word2Vec module of the gensim library.\n",
    "3. Extract all embedding data and write it to chDB.\n",
    "4. Perform queries on chDB based on cosine distance to find similar movies to the input movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Briefing about Word2Vec\n",
    "\n",
    "Word2Vec was introduced in two papers by a team of researchers at Google, published between September and October 2013. Alongside the papers, the researchers released their implementation in C. The Python implementation followed shortly after the first paper, courtesy of Gensim.\n",
    "\n",
    "The fundamental premise of Word2Vec is that words with similar contexts also have similar meanings and consequently share a comparable vector representation within the model. For example, \"dog,\" \"puppy,\" and \"pup\" are frequently used in analogous situations with similar surrounding words like \"good,\" \"fluffy,\" or \"cute.\" According to Word2Vec, they will thus possess a corresponding vector representation.\n",
    "\n",
    "Based on this assumption, Word2Vec can be utilized to discover relationships between words in a dataset, calculate their similarity, or employ the vector representation of these words as input for other applications such as text classification or clustering.\n",
    "\n",
    "<img src=\"https://mccormickml.com/assets/word2vec/skip_gram_net_arch.png\" alt=\"Word2Vec\" style=\"max-width:800px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Name: tensorflow-cpu\n",
      "Version: 2.15.0.post1\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /home/Clickhouse/.venv/lib/python3.9/site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: \n",
      "---\n",
      "Name: chdb\n",
      "Version: 1.0.2\n",
      "Summary: chDB is an in-process SQL OLAP Engine powered by ClickHouse\n",
      "Home-page: https://github.com/auxten/chdb\n",
      "Author: auxten\n",
      "Author-email: auxtenwpc@gmail.com\n",
      "License: Apache-2.0\n",
      "Location: /home/Clickhouse/.venv/lib/python3.9/site-packages\n",
      "Requires: \n",
      "Required-by: \n",
      "---\n",
      "Name: gensim\n",
      "Version: 4.3.2\n",
      "Summary: Python framework for fast Vector Space Modelling\n",
      "Home-page: https://radimrehurek.com/gensim/\n",
      "Author: Radim Rehurek\n",
      "Author-email: me@radimrehurek.com\n",
      "License: LGPL-2.1-only\n",
      "Location: /home/Clickhouse/.venv/lib/python3.9/site-packages\n",
      "Requires: numpy, scipy, smart-open\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -i https://pypi.tuna.tsinghua.edu.cn/simple --upgrade tensorflow-cpu gensim chdb pandas pyarrow scikit-learn numpy matplotlib\n",
    "%pip show tensorflow-cpu chdb gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1129584\n",
      "-rw-r--r-- 1 root root     10460 Dec 11 08:24 README.txt\n",
      "-rw-r--r-- 1 root root 435164157 Dec 11 08:24 genome-scores.csv\n",
      "-rw-r--r-- 1 root root     18103 Dec 11 08:24 genome-tags.csv\n",
      "-rw-r--r-- 1 root root   1368578 Dec 11 08:24 links.csv\n",
      "-rw-r--r-- 1 root root   3038099 Dec 11 08:24 movies.csv\n",
      "-rw-r--r-- 1 root root 678260987 Dec 11 08:24 ratings.csv\n",
      "-rw-r--r-- 1 root root  38810332 Dec 11 08:24 tags.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import os\n",
    "import chdb\n",
    "from chdb import session\n",
    "\n",
    "# Download and extract the dataset\n",
    "if not os.path.exists(\"ml-25m/ratings.csv\"):\n",
    "    url = \"https://files.grouplens.org/datasets/movielens/ml-25m.zip\"\n",
    "    import ssl\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    filehandle, _ = urllib.request.urlretrieve(url)\n",
    "    zip_file_object = zipfile.ZipFile(filehandle, \"r\")\n",
    "    zip_file_object.extractall()\n",
    "\n",
    "!ls -l ml-25m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,296,5,1147880044\n",
      "1,306,3.5,1147868817\n",
      "1,307,5,1147868828\n",
      "1,665,5,1147878820\n",
      "1,899,3.5,1147868510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Peek at the data\n",
    "print(chdb.query(\"SELECT * FROM file('ml-25m/ratings.csv') LIMIT 5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"movieId\",\"title\",\"genres\"\n",
      "1,\"Toy Story (1995)\",\"Adventure|Animation|Children|Comedy|Fantasy\"\n",
      "2,\"Jumanji (1995)\",\"Adventure|Children|Fantasy\"\n",
      "3,\"Grumpier Old Men (1995)\",\"Comedy|Romance\"\n",
      "4,\"Waiting to Exhale (1995)\",\"Comedy|Drama|Romance\"\n",
      "5,\"Father of the Bride Part II (1995)\",\"Comedy\"\n",
      "\n",
      "\"userId\",\"movieId\",\"rating\",\"timestamp\"\n",
      "1,296,5,1147880044\n",
      "1,306,3.5,1147868817\n",
      "1,307,5,1147868828\n",
      "1,665,5,1147878820\n",
      "1,899,3.5,1147868510\n",
      "\n",
      "\"userId\",\"movieId\",\"tag\",\"timestamp\"\n",
      "3,260,\"classic\",1439472355\n",
      "3,260,\"sci-fi\",1439472256\n",
      "4,1732,\"dark comedy\",1573943598\n",
      "4,1732,\"great dialogue\",1573943604\n",
      "4,7569,\"so bad it's good\",1573943455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create tables for the tables of movieLens dataset\n",
    "chs = session.Session()\n",
    "chs.query(\"CREATE DATABASE IF NOT EXISTS movielens ENGINE = Atomic\")\n",
    "chs.query(\"USE movielens\")\n",
    "chs.query(\n",
    "    \"CREATE VIEW movies AS SELECT movieId, title, genres FROM file('ml-25m/movies.csv')\"\n",
    ")\n",
    "chs.query(\n",
    "    \"CREATE VIEW ratings AS SELECT userId, movieId, rating, timestamp FROM file('ml-25m/ratings.csv')\"\n",
    ")\n",
    "chs.query(\n",
    "    \"CREATE VIEW tags AS SELECT userId, movieId, tag, timestamp FROM file('ml-25m/tags.csv')\"\n",
    ")\n",
    "print(chs.query(\"SELECT * FROM movies LIMIT 5\", \"CSVWithNames\"))\n",
    "print(chs.query(\"SELECT * FROM ratings LIMIT 5\", \"CSVWithNames\"))\n",
    "print(chs.query(\"SELECT * FROM tags LIMIT 5\", \"CSVWithNames\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use word2vec to train the embeddings of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of movie list:  162343\n",
      "First 5 movie list:  ['\"858 1193 2959 50 183837 201773 122914 195159 8961 33794 6377 1203 904 912 2019 79132 58559 593 4226 122912 122916 4973 750 122926 68954 3504 955 4963 8984 53322 158783 45720 117887 178827 171253 1387 6533 49272 71745 154 7209 164909 1256 166461 2648 1340 5769 1198 1732 91094 1265 6893 1945 307 104283 3645 2716 1 78499 3114 201588 898 3546 1220 2936 50872 364 4262 200332 1079 195161 2700 946 1267 180031 953 176371 6273 111734 152970 35836 26393 164179 118466 25865 127202 56782 4361 1276 134853 5712 2065 61934 2761 145150 3362 3928 108932 112852 103980 7064 2423 8360 112450 141 82926 916 3039 2203 2132 3088 26171 951 1148 8641 60756 34162 106918 3948 1923 83976 1682 3988 1485 6373 180265 72294 3556 2987 2406 4681 188301 89745 59315 122920 288 38061 102125 2770 79702 110102 93840 104913 8798 142488 106920 6711 137857 111781 111759 648 1961 45186 189333 55820 139644 158872 69122 140174 93510 169992 122906 185029 5989 56152 4022 150 2797 2424 105504 107141 1042 3741 122882 189363 954 3836 1580 197711 4306 4886 5418 54286 8665 6333 48394 8874 3751 46578 4246 51255 6863 48774 76093 4720 112556 4848 8464 5991 57669 96079 119145 7451 61323 115569 5444 168252 56757 115149 72011 89492 80549 88163 38038 8638 168250 4728 177765 171763 112138 6867 177593 65261 6296 158238 6550 140110 1950 1291 589 1270 1036 1200 457 1097 2762 1240 1214 1307 1028 480 915 3307 910 908 909 3175 899 922 926 7206 6787 179135 26662 5618 1234 6001 160718 171011 115122 745 4002 159817 2795 3072 170355 100714 1225 3462 175303 4499 2687 3022 1281 905 2355 178061 215 3499 1223 2291 3736 102993 189713 1394 141924 151455 3176 2599 2763 950 500 936 1449 2746 3310 1407 830 47 608 924 32 183869 586 183611 377 3089 595 52975 6936 117438 2791 3365 8235 93838 110501 174909 1377 2948 134368 1226 2245 317 113064 3247 2953 935 89118 106438 104272 96832 114028 65514 64285 4920 1304 134849 2940 918 146656 162082 2102 1292 3996 4144 7981 232 203218 25750 1673 7587 1213 2083 2935 8767 900 7013 1946 7073 3435 198185 2366 7132 127152 179173 5017 947 4298 5291 1982 4432 945 7706 8542 34018 2413 8620 47721 25826 208651 207367 86295 1717 31851 5419 8044 2363 410 204704 3635\"', '\"1266 1466 2871 2288 1732 3328 54997 6539 296 356 555 1464 4848 2019 2571 2858 858 4993 2997 714 68159 1220 97752 2947 741 1199 1921 3000 1079 1200 32 99114 6 1653 1527 5060 1080 2692 1127 1279 4973 86882 50 527 318 1221 1193 1198 3578 5952 7153 3996 109374 68954 33004 1201 47 55247 80906 1729 541 750 1203 117533 115713 112183 120466 64614 1036 67255 96488 70286 69524 5989 1243 60766 1270 106920 55269 72226 108983 72356 4370 83803 84156 106918 128360 68157 109487 117444 94864 117887 178827 2959 68237 158966 176371 1682 48774 179133 5418 193950 84944 42734 152081 588 95167 2161 316 69644\"', '\"1779 175 839 5903 8957 6874 592 1198 5445 2571 7361 4226 4995 1210 608 2959 32587 60832 55820 318 527 32 1617 2858 296 1240 56367 316 1527 733 47 26903 1291 593 1704 260 7438 2916 50 2683 1193 3996 51255 60291 1214 48385 253 1200 2174 2700 1682 2291 541 1517 5669 454 1784 48516 4878 60522 3481 1221 858 2997 54503 8622 1036 3052 3147 61167 4011 1573 8874 6 1213 2329 3176 1208 8784 2194 3527 3948\"', '\"1296 1959 2384 1693 1672 2764 1307 912 318 908 2959 79132 1197\"', '\"1466 2019 3949 296 589 527 608 2858 858 1221 1208 1333 5015\"']\n"
     ]
    }
   ],
   "source": [
    "# Generate the movie id sequence from user ratings, the movies that have been rated >3.5 by users group by userId\n",
    "# and concat with \" \", order by timestamp\n",
    "# The movie id sequence is used to generate the movie embedding,\n",
    "# ie. user 1 rated movie 233, 21, 11 and user 2 rated movie 33, 11, 21\n",
    "# then the movie id sequence is\n",
    "# \"233 21 11\"\n",
    "# \"33 11 21\"\n",
    "movie_id_seq = chs.query(\"\"\"SELECT arrayStringConcat(groupArray(movieId), ' ') FROM (\n",
    "                            SELECT userId, movieId FROM ratings WHERE rating > 3.5  ORDER BY userId, timestamp\n",
    "                            ) GROUP BY userId\"\"\")   \n",
    "\n",
    "\n",
    "# Split the movie id sequence into list\n",
    "moive_list = str(movie_id_seq).split(\"\\n\")\n",
    "\n",
    "print(\"Length of movie list: \", len(moive_list))\n",
    "print(\"First 5 movie list: \", moive_list[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of movie id sequence list:  162343\n",
      "First 5 movie id sequence list:  [['858', '1193', '2959', '50', '183837', '201773', '122914', '195159', '8961', '33794', '6377', '1203', '904', '912', '2019', '79132', '58559', '593', '4226', '122912', '122916', '4973', '750', '122926', '68954', '3504', '955', '4963', '8984', '53322', '158783', '45720', '117887', '178827', '171253', '1387', '6533', '49272', '71745', '154', '7209', '164909', '1256', '166461', '2648', '1340', '5769', '1198', '1732', '91094', '1265', '6893', '1945', '307', '104283', '3645', '2716', '1', '78499', '3114', '201588', '898', '3546', '1220', '2936', '50872', '364', '4262', '200332', '1079', '195161', '2700', '946', '1267', '180031', '953', '176371', '6273', '111734', '152970', '35836', '26393', '164179', '118466', '25865', '127202', '56782', '4361', '1276', '134853', '5712', '2065', '61934', '2761', '145150', '3362', '3928', '108932', '112852', '103980', '7064', '2423', '8360', '112450', '141', '82926', '916', '3039', '2203', '2132', '3088', '26171', '951', '1148', '8641', '60756', '34162', '106918', '3948', '1923', '83976', '1682', '3988', '1485', '6373', '180265', '72294', '3556', '2987', '2406', '4681', '188301', '89745', '59315', '122920', '288', '38061', '102125', '2770', '79702', '110102', '93840', '104913', '8798', '142488', '106920', '6711', '137857', '111781', '111759', '648', '1961', '45186', '189333', '55820', '139644', '158872', '69122', '140174', '93510', '169992', '122906', '185029', '5989', '56152', '4022', '150', '2797', '2424', '105504', '107141', '1042', '3741', '122882', '189363', '954', '3836', '1580', '197711', '4306', '4886', '5418', '54286', '8665', '6333', '48394', '8874', '3751', '46578', '4246', '51255', '6863', '48774', '76093', '4720', '112556', '4848', '8464', '5991', '57669', '96079', '119145', '7451', '61323', '115569', '5444', '168252', '56757', '115149', '72011', '89492', '80549', '88163', '38038', '8638', '168250', '4728', '177765', '171763', '112138', '6867', '177593', '65261', '6296', '158238', '6550', '140110', '1950', '1291', '589', '1270', '1036', '1200', '457', '1097', '2762', '1240', '1214', '1307', '1028', '480', '915', '3307', '910', '908', '909', '3175', '899', '922', '926', '7206', '6787', '179135', '26662', '5618', '1234', '6001', '160718', '171011', '115122', '745', '4002', '159817', '2795', '3072', '170355', '100714', '1225', '3462', '175303', '4499', '2687', '3022', '1281', '905', '2355', '178061', '215', '3499', '1223', '2291', '3736', '102993', '189713', '1394', '141924', '151455', '3176', '2599', '2763', '950', '500', '936', '1449', '2746', '3310', '1407', '830', '47', '608', '924', '32', '183869', '586', '183611', '377', '3089', '595', '52975', '6936', '117438', '2791', '3365', '8235', '93838', '110501', '174909', '1377', '2948', '134368', '1226', '2245', '317', '113064', '3247', '2953', '935', '89118', '106438', '104272', '96832', '114028', '65514', '64285', '4920', '1304', '134849', '2940', '918', '146656', '162082', '2102', '1292', '3996', '4144', '7981', '232', '203218', '25750', '1673', '7587', '1213', '2083', '2935', '8767', '900', '7013', '1946', '7073', '3435', '198185', '2366', '7132', '127152', '179173', '5017', '947', '4298', '5291', '1982', '4432', '945', '7706', '8542', '34018', '2413', '8620', '47721', '25826', '208651', '207367', '86295', '1717', '31851', '5419', '8044', '2363', '410', '204704', '3635'], ['1266', '1466', '2871', '2288', '1732', '3328', '54997', '6539', '296', '356', '555', '1464', '4848', '2019', '2571', '2858', '858', '4993', '2997', '714', '68159', '1220', '97752', '2947', '741', '1199', '1921', '3000', '1079', '1200', '32', '99114', '6', '1653', '1527', '5060', '1080', '2692', '1127', '1279', '4973', '86882', '50', '527', '318', '1221', '1193', '1198', '3578', '5952', '7153', '3996', '109374', '68954', '33004', '1201', '47', '55247', '80906', '1729', '541', '750', '1203', '117533', '115713', '112183', '120466', '64614', '1036', '67255', '96488', '70286', '69524', '5989', '1243', '60766', '1270', '106920', '55269', '72226', '108983', '72356', '4370', '83803', '84156', '106918', '128360', '68157', '109487', '117444', '94864', '117887', '178827', '2959', '68237', '158966', '176371', '1682', '48774', '179133', '5418', '193950', '84944', '42734', '152081', '588', '95167', '2161', '316', '69644'], ['1779', '175', '839', '5903', '8957', '6874', '592', '1198', '5445', '2571', '7361', '4226', '4995', '1210', '608', '2959', '32587', '60832', '55820', '318', '527', '32', '1617', '2858', '296', '1240', '56367', '316', '1527', '733', '47', '26903', '1291', '593', '1704', '260', '7438', '2916', '50', '2683', '1193', '3996', '51255', '60291', '1214', '48385', '253', '1200', '2174', '2700', '1682', '2291', '541', '1517', '5669', '454', '1784', '48516', '4878', '60522', '3481', '1221', '858', '2997', '54503', '8622', '1036', '3052', '3147', '61167', '4011', '1573', '8874', '6', '1213', '2329', '3176', '1208', '8784', '2194', '3527', '3948'], ['1296', '1959', '2384', '1693', '1672', '2764', '1307', '912', '318', '908', '2959', '79132', '1197'], ['1466', '2019', '3949', '296', '589', '527', '608', '2858', '858', '1221', '1208', '1333', '5015']]\n",
      "Vocabulary size:  40858\n",
      "Distinct movie id count:  40858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Split the movie id sequence into a list of lists\n",
    "movie_id_seq_list = [seq.strip(\"\\\"\").split() for seq in moive_list]\n",
    "print(\"Length of movie id sequence list: \", len(movie_id_seq_list))\n",
    "print(\"First 5 movie id sequence list: \", movie_id_seq_list[:5])\n",
    "\n",
    "# Train the Word2Vec model using CBOW\n",
    "model = Word2Vec(sg=0, window=5, vector_size=16, min_count=1, workers=cores-1)\n",
    "model.build_vocab(movie_id_seq_list, progress_per=10000)\n",
    "print(\"Vocabulary size: \", len(model.wv))\n",
    "\n",
    "# Check the distinct movie id with at least one rating > 3.5 count\n",
    "print(\"Distinct movie id count: \", chs.query(\"SELECT count(DISTINCT movieId) FROM ratings WHERE rating > 3.5\"))\n",
    "\n",
    "model.train(movie_id_seq_list, total_examples=model.corpus_count, epochs=10, report_delay=1)\n",
    "\n",
    "# Print model info\n",
    "print(\"Vocabulary content: \", model.wv.index_to_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test find similar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input movie:  \"Toy Story (1995)\"\n",
      "\n",
      "Top 10 similar movies: \n",
      "34,\"Babe (1995)\"\n",
      "150,\"Apollo 13 (1995)\"\n",
      "356,\"Forrest Gump (1994)\"\n",
      "364,\"Lion King, The (1994)\"\n",
      "588,\"Aladdin (1992)\"\n",
      "595,\"Beauty and the Beast (1991)\"\n",
      "1197,\"Princess Bride, The (1987)\"\n",
      "1265,\"Groundhog Day (1993)\"\n",
      "1270,\"Back to the Future (1985)\"\n",
      "3114,\"Toy Story 2 (1999)\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_movie_id = 1\n",
    "top_k = 10\n",
    "print(\"Input movie: \", chs.query(f\"SELECT title FROM movies WHERE movieId = {input_movie_id}\", \"CSV\"))\n",
    "print(\"Top 10 similar movies: \")\n",
    "similar_movies = model.wv.most_similar(str(input_movie_id), topn=top_k)\n",
    "print(chs.query(f\"SELECT movieId, title FROM movies WHERE movieId IN ({','.join([str(m[0]) for m in similar_movies])})\", \"CSV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save movieId and embeddings to a temporary CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/Clickhouse/examples/chDB_vector_search.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636c616e673135222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6169702d6465763032227d7d/home/Clickhouse/examples/chDB_vector_search.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m embedding \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mwv[movieId]\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636c616e673135222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6169702d6465763032227d7d/home/Clickhouse/examples/chDB_vector_search.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Convert the format [0.1 0.2 ...] into a list of floats, eg. [0.1, 0.2, ...]\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636c616e673135222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6169702d6465763032227d7d/home/Clickhouse/examples/chDB_vector_search.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m embedding \u001b[39m=\u001b[39m embedding[\u001b[39m1\u001b[39;49m:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49msplit()\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636c616e673135222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6169702d6465763032227d7d/home/Clickhouse/examples/chDB_vector_search.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Write the movieId and embedding as a row in the CSV file\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636c616e673135222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6169702d6465763032227d7d/home/Clickhouse/examples/chDB_vector_search.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m writer\u001b[39m.\u001b[39mwriterow([movieId, embedding])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open('movie_embeddings.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow(['movieId', 'embedding'])\n",
    "\n",
    "    # Iterate over each movieId and its corresponding embedding\n",
    "    for movieId in model.wv.index_to_key:\n",
    "        embedding = model.wv[movieId]\n",
    "        # Convert the format [0.1 0.2 ...] into a list of floats, eg. [0.1, 0.2, ...]\n",
    "        embedding = embedding.tolist()\n",
    "\n",
    "        # Write the movieId and embedding as a row in the CSV file\n",
    "        writer.writerow([movieId, embedding])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use brute force to find similar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318,\"[-0.92671806  4.0658607  -0.9362241   2.3389215  -5.5646834  -3.0489233\n",
       " -2.3870916  -3.9461932   2.5411336  -4.2200975   2.2373397   4.5567446\n",
       "  4.2845583  -0.27262357  1.7597772  -0.7714879 ]\"\n",
       "296,\"[-2.320194    2.9284086  -0.23645285  0.8121122  -6.580175   -2.6938596\n",
       " -4.4205527  -3.6644669   3.6217701  -4.7963047   2.8589551   2.1375341\n",
       "  1.4287919   1.2680439   1.5670657  -0.12797607]\"\n",
       "356,\"[-2.8729887   2.6795983  -3.0608099   0.34714407 -2.6804838  -2.955097\n",
       " -4.0935082  -2.248234    1.4665883  -3.4244392   1.334923    5.6284447\n",
       "  2.4682024   1.7087619   2.0542164  -2.622762  ]\"\n",
       "593,\"[-3.350593    3.40134    -2.7125394   1.3866315  -6.415367   -4.108528\n",
       " -3.4653835  -4.563889    3.4765499  -4.066826    1.3893566   3.6057796\n",
       "  1.9603899   0.25266844  1.17256    -0.29026085]\"\n",
       "2571,\"[-2.725035    3.2000797  -1.1294255   3.7750504  -6.250042   -3.7862737\n",
       " -3.8041484  -2.58676     0.06922363 -0.8518675   4.711027    4.6145434\n",
       "  1.7265469   4.670463   -0.9652608   0.14176556]\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chs.query('SELECT * FROM file(\\'movie_embeddings.csv\\') LIMIT 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the movie_embeddings database\n",
    "from chdb import session\n",
    "chs = session.Session()\n",
    "chs.query(\"CREATE DATABASE IF NOT EXISTS movie_embeddings ENGINE = Atomic\")\n",
    "chs.query(\"USE movie_embeddings\")\n",
    "chs.query('DROP TABLE IF EXISTS embeddings')\n",
    "chs.query('DROP TABLE IF EXISTS embeddings_with_title')\n",
    "\n",
    "\n",
    "chs.query(\"\"\"CREATE TABLE embeddings (\n",
    "      movieId UInt32 NOT NULL,\n",
    "      embedding Array(Float32) NOT NULL\n",
    "  ) ENGINE = MergeTree()\n",
    "  ORDER BY movieId\"\"\")\n",
    "\n",
    "print(\"Inserting movie embeddings into the database\")\n",
    "chs.query(\"INSERT INTO embeddings (movieId, embedding) VALUES (318, [-0.92671806, 4.0658607, -0.9362241, 2.3389215, -5.5646834, -3.0489233, -2.3870916, -3.9461932, 2.5411336, -4.2200975, 2.2373397, 4.5567446, 4.2845583, -0.27262357, 1.7597772, -0.7714879])\")\n",
    "\n",
    "print(chs.query('SELECT * FROM embeddings LIMIT 5'))\n",
    "\n",
    "\n",
    "# # Join the embeddings table with the movies table to get the title\n",
    "# chs.query('CREATE TABLE embeddings_with_title '\n",
    "#           '(movieId UInt32 NOT NULL, title String NOT NULL, embedding Array(Float32) NOT NULL) '\n",
    "#             'ENGINE = MergeTree() '\n",
    "#             'ORDER BY movieId '\n",
    "#             'AS SELECT e.movieId, m.title, e.embedding '\n",
    "#             'FROM file(\\'movie_embeddings.csv\\') AS e '\n",
    "#             'JOIN movielens.movies AS m ON e.movieId = m.movieId')\n",
    "\n",
    "\n",
    "# print(chs.query('SELECT * FROM embeddings_with_title LIMIT 5'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
