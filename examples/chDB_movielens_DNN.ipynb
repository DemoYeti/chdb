{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: tensorflow-cpu in /home/Clickhouse/.venv/lib/python3.9/site-packages (2.15.0.post1)\n",
      "Requirement already satisfied: chdb in /home/Clickhouse/.venv/lib/python3.9/site-packages (1.0.1)\n",
      "Requirement already satisfied: pandas in /home/Clickhouse/.venv/lib/python3.9/site-packages (2.1.4)\n",
      "Requirement already satisfied: pyarrow in /home/Clickhouse/.venv/lib/python3.9/site-packages (14.0.1)\n",
      "Requirement already satisfied: scikit-learn in /home/Clickhouse/.venv/lib/python3.9/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy in /home/Clickhouse/.venv/lib/python3.9/site-packages (1.26.2)\n",
      "Requirement already satisfied: matplotlib in /home/Clickhouse/.venv/lib/python3.9/site-packages (3.8.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (69.0.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorflow-cpu) (2.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from matplotlib) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from matplotlib) (6.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.42.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-cpu) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-cpu) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-cpu) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-cpu) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow-cpu) (7.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-cpu) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-cpu) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-cpu) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-cpu) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-cpu) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-cpu) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/Clickhouse/.venv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-cpu) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --upgrade tensorflow-cpu chdb pandas pyarrow scikit-learn numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1129584\n",
      "-rw-r--r-- 1 root root     10460 Dec 11 08:24 README.txt\n",
      "-rw-r--r-- 1 root root 435164157 Dec 11 08:24 genome-scores.csv\n",
      "-rw-r--r-- 1 root root     18103 Dec 11 08:24 genome-tags.csv\n",
      "-rw-r--r-- 1 root root   1368578 Dec 11 08:24 links.csv\n",
      "-rw-r--r-- 1 root root   3038099 Dec 11 08:24 movies.csv\n",
      "-rw-r--r-- 1 root root 678260987 Dec 11 08:24 ratings.csv\n",
      "-rw-r--r-- 1 root root  38810332 Dec 11 08:24 tags.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import os\n",
    "import chdb\n",
    "from chdb import session\n",
    "\n",
    "# Download and extract the dataset\n",
    "if not os.path.exists(\"ml-25m/ratings.csv\"):\n",
    "    url = \"https://files.grouplens.org/datasets/movielens/ml-25m.zip\"\n",
    "    import ssl\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    filehandle, _ = urllib.request.urlretrieve(url)\n",
    "    zip_file_object = zipfile.ZipFile(filehandle, \"r\")\n",
    "    zip_file_object.extractall()\n",
    "\n",
    "!ls -l ml-25m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,296,5,1147880044\n",
      "1,306,3.5,1147868817\n",
      "1,307,5,1147868828\n",
      "1,665,5,1147878820\n",
      "1,899,3.5,1147868510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Peek at the data\n",
    "print(chdb.query(\"SELECT * FROM file('ml-25m/ratings.csv') LIMIT 5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create views for the tables of movieLens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"movieId\",\"title\",\"genres\"\n",
      "1,\"Toy Story (1995)\",\"Adventure|Animation|Children|Comedy|Fantasy\"\n",
      "2,\"Jumanji (1995)\",\"Adventure|Children|Fantasy\"\n",
      "3,\"Grumpier Old Men (1995)\",\"Comedy|Romance\"\n",
      "4,\"Waiting to Exhale (1995)\",\"Comedy|Drama|Romance\"\n",
      "5,\"Father of the Bride Part II (1995)\",\"Comedy\"\n",
      "\n",
      "\"userId\",\"movieId\",\"rating\",\"timestamp\"\n",
      "1,296,5,1147880044\n",
      "1,306,3.5,1147868817\n",
      "1,307,5,1147868828\n",
      "1,665,5,1147878820\n",
      "1,899,3.5,1147868510\n",
      "\n",
      "\"userId\",\"movieId\",\"tag\",\"timestamp\"\n",
      "3,260,\"classic\",1439472355\n",
      "3,260,\"sci-fi\",1439472256\n",
      "4,1732,\"dark comedy\",1573943598\n",
      "4,1732,\"great dialogue\",1573943604\n",
      "4,7569,\"so bad it's good\",1573943455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create tables for the tables of movieLens dataset\n",
    "chs = session.Session()\n",
    "chs.query(\"CREATE DATABASE IF NOT EXISTS movielens ENGINE = Atomic\")\n",
    "chs.query(\"USE movielens\")\n",
    "chs.query(\n",
    "    \"CREATE VIEW movies AS SELECT movieId, title, genres FROM file('ml-25m/movies.csv')\"\n",
    ")\n",
    "chs.query(\n",
    "    \"CREATE VIEW ratings AS SELECT userId, movieId, rating, timestamp FROM file('ml-25m/ratings.csv')\"\n",
    ")\n",
    "chs.query(\n",
    "    \"CREATE VIEW tags AS SELECT userId, movieId, tag, timestamp FROM file('ml-25m/tags.csv')\"\n",
    ")\n",
    "print(chs.query(\"SELECT * FROM movies LIMIT 5\", \"CSVWithNames\"))\n",
    "print(chs.query(\"SELECT * FROM ratings LIMIT 5\", \"CSVWithNames\"))\n",
    "print(chs.query(\"SELECT * FROM tags LIMIT 5\", \"CSVWithNames\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a view to join the movies/ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"userId\",\"movieId\",\"title\",\"genres\",\"liked\"\n",
      "1,296,\"Pulp Fiction (1994)\",\"Comedy|Crime|Drama|Thriller\",1\n",
      "1,306,\"Three Colors: Red (Trois couleurs: Rouge) (1994)\",\"Drama\",0\n",
      "1,307,\"Three Colors: Blue (Trois couleurs: Bleu) (1993)\",\"Drama\",1\n",
      "1,665,\"Underground (1995)\",\"Comedy|Drama|War\",1\n",
      "1,899,\"Singin' in the Rain (1952)\",\"Comedy|Musical|Romance\",0\n",
      "\n",
      "Training rows: 19994500\n",
      "\n",
      "Test rows: 5005595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a view to join the movies/ratings, if user rating >3.5 to a movie then 1(like) else 0(dislike)\n",
    "chs.query(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE VIEW user_ratings AS\n",
    "        SELECT ratings.userId userId, ratings.movieId movieId, movies.title title, genres,\n",
    "            CASE WHEN rating > 3.5 THEN 1 ELSE 0 END AS liked\n",
    "        FROM ratings\n",
    "        JOIN movies USING movieId\n",
    "    \"\"\"\n",
    ")\n",
    "# Peek at the data\n",
    "print(chs.query(\"SELECT * FROM user_ratings LIMIT 5\", \"CSVWithNames\"))\n",
    "\n",
    "# Split the data into train and test with userId\n",
    "chs.query(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE VIEW train AS\n",
    "        SELECT userId, movieId, title, genres, liked\n",
    "        FROM user_ratings\n",
    "        WHERE userId % 10 < 8;\n",
    "    CREATE OR REPLACE VIEW test AS\n",
    "        SELECT userId, movieId, title, genres, liked\n",
    "        FROM user_ratings\n",
    "        WHERE userId % 10 >= 8;\n",
    "    \"\"\"\n",
    ")\n",
    "# Count the number of rows in train and test\n",
    "print(\"Training rows:\", chs.query(\"SELECT COUNT(*) FROM train\"))\n",
    "print(\"Test rows:\", chs.query(\"SELECT COUNT(*) FROM test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a DNN model to predict if a user will like a movie or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample: [1 296 'Pulp Fiction (1994)' 'Comedy|Crime|Drama|Thriller']\n",
      "y_train sample: 1\n",
      "X_val sample: [8 1 'Toy Story (1995)' 'Adventure|Animation|Children|Comedy|Fantasy']\n",
      "y_val sample: 1\n",
      "X_train sample: [1 296 'Pulp Fiction (1994)' 'Comedy|Crime|Drama|Thriller' 1994]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "train_data = chs.query(\n",
    "    \"SELECT userId, movieId, title, genres, liked FROM train\", \"DataFrame\"\n",
    ")\n",
    "validate_data = chs.query(\n",
    "    \"SELECT userId, movieId, title, genres, liked FROM test\", \"DataFrame\"\n",
    ")\n",
    "\n",
    "# # Convert the data to numpy 2d array\n",
    "# data = data.values\n",
    "\n",
    "# # Split the data into features and labels\n",
    "# X = data[:, :-1]\n",
    "# y = data[:, -1]\n",
    "\n",
    "# # Split the data into training and validation sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = train_data.values[:, :-1]\n",
    "y_train = train_data.values[:, -1]\n",
    "X_val = validate_data.values[:, :-1]\n",
    "y_val = validate_data.values[:, -1]\n",
    "\n",
    "print(\"X_train sample:\", X_train[0])\n",
    "print(\"y_train sample:\", y_train[0])\n",
    "print(\"X_val sample:\", X_val[0])\n",
    "print(\"y_val sample:\", y_val[0])\n",
    "\n",
    "# Split the movie title to extract the shooting year as a feature\n",
    "# eg. Toy Story (1995) -> 1995 if the title has no year, use 1900 instead\n",
    "def get_year(title):\n",
    "    try:\n",
    "        return int(title.split(\"(\")[-1].split(\")\")[0].split(\"-\")[0])\n",
    "    except:\n",
    "        return 1900\n",
    "title_years = np.array(\n",
    "    [get_year(title) for title in X_train[:, 2]]\n",
    ")\n",
    "X_train = np.concatenate((X_train, title_years[:, np.newaxis]), axis=1)\n",
    "print(\"X_train sample:\", X_train[0])\n",
    "\n",
    "# Split the genres by \"|\" to make the genre as a sparse feature by\n",
    "# one-hot encoding\n",
    "\n",
    "\n",
    "# genres_sparse = np.array([genre.split(\"|\") for genre in X_train[:, 3]])\n",
    "# X_train = np.concatenate((X_train, genres_sparse), axis=1)\n",
    "\n",
    "# # Define the model architecture\n",
    "# model = tf.keras.Sequential(\n",
    "#     [\n",
    "#         tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "#         tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "#         tf.keras.layers.Dense(1),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(\n",
    "#     X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32\n",
    "# )\n",
    "\n",
    "# # Evaluate the model\n",
    "# X_val_title_years = np.array(\n",
    "#     [int(title.split(\"(\")[-1].split(\")\")[0]) for title in X_val[:, 3]]\n",
    "# )\n",
    "# X_val_genres_sparse = np.array([genre.split(\"|\") for genre in X_val[:, 4]])\n",
    "# X_val = np.concatenate(\n",
    "#     (X_val, X_val_title_years[:, np.newaxis], X_val_genres_sparse), axis=1\n",
    "# )\n",
    "\n",
    "# y_pred = model.predict(X_val)\n",
    "# rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "# print(\"RMSE:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
